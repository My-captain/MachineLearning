{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2238783",
   "metadata": {},
   "source": [
    "### 使用nn.Module和nn.functional实现神经网络\n",
    "\n",
    "'nn.Module'用来实现自定义的网络（或部分的网络），需要实现：\n",
    "- '__init__(self, ...)': 网络的初始化\n",
    "- 'forward(self, x)': 网络的前馈过程\n",
    "\n",
    "'nn.Module'的常用方法：\n",
    "- 'zero_grad()': 清空所有层的梯度\n",
    "- 'train()': 训练模式\n",
    "- 'eval()': 测试模式\n",
    "- 'cuda()'/'cpu()': 将整个网络（所有层）迁移到GPU或CPU上\n",
    "- 'parameters()': 返回所有的参数（在初始化的时候有可能使用到）\n",
    "\n",
    "常用的组件：\n",
    "- 'nn.Conv2d': 二维卷积层\n",
    "- 'nn.Linear': 全连接层\n",
    "- 'nn.MaxPool2d'/'nn.AvgPool2d': Pooling层\n",
    "- 'nn.ReLU': ReLU层\n",
    "- 'nn.Dropout': Dropout层\n",
    "- 'BatchNorm2d': BatchNorm层\n",
    "\n",
    "'nn.Module'和'nn.functional'的关系：\n",
    "'nn.Module'是对'nn.functional'的封装，将定义权重的过程封装起来，使用更方便。\n",
    "对于一些没有参数的层，使用'nn.functional'中的函数可能会更方便一些。\n",
    "\n",
    "训练与测试：以MNIST为例\n",
    "- 数据读入\n",
    "- 初始化模型、优化器\n",
    "- 训练、测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742507e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T05:33:30.714001Z",
     "iopub.status.busy": "2022-04-24T05:33:30.713597Z",
     "iopub.status.idle": "2022-04-24T05:33:32.123790Z",
     "shell.execute_reply": "2022-04-24T05:33:32.122935Z",
     "shell.execute_reply.started": "2022-04-24T05:33:30.713951Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 使用nn.Module和nn.functional实现MLP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = F.softmax(self.fc2(x), dim=0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92de73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T05:33:32.125659Z",
     "iopub.status.busy": "2022-04-24T05:33:32.125414Z",
     "iopub.status.idle": "2022-04-24T05:33:32.337562Z",
     "shell.execute_reply": "2022-04-24T05:33:32.336209Z",
     "shell.execute_reply.started": "2022-04-24T05:33:32.125632Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = MLPNet()\n",
    "\n",
    "data = torch.ones(50, 100)\n",
    "out = net(data)\n",
    "\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993f692a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T05:33:32.340489Z",
     "iopub.status.busy": "2022-04-24T05:33:32.339999Z",
     "iopub.status.idle": "2022-04-24T05:33:32.438509Z",
     "shell.execute_reply": "2022-04-24T05:33:32.437101Z",
     "shell.execute_reply.started": "2022-04-24T05:33:32.340432Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(3136, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = x.view((x.shape[0],28,28))\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864a5720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T05:33:32.440968Z",
     "iopub.status.busy": "2022-04-24T05:33:32.440535Z",
     "iopub.status.idle": "2022-04-24T05:33:32.610322Z",
     "shell.execute_reply": "2022-04-24T05:33:32.609234Z",
     "shell.execute_reply.started": "2022-04-24T05:33:32.440918Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "\n",
    "def get_MNIST_dataloader(batch_size=64):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=datasets.MNIST('./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7f3227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T05:33:32.612422Z",
     "iopub.status.busy": "2022-04-24T05:33:32.612057Z",
     "iopub.status.idle": "2022-04-24T05:33:32.619449Z",
     "shell.execute_reply": "2022-04-24T05:33:32.618849Z",
     "shell.execute_reply.started": "2022-04-24T05:33:32.612378Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_on_MNIST(init_lr=1e-4, num_epochs=10, device=torch.device(\"cuda\")):\n",
    "    train_loader, test_loader = get_MNIST_dataloader()\n",
    "\n",
    "    # prepare model and optimizer\n",
    "    model = Model().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=init_lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(1, 1+num_epochs):\n",
    "        train_one_epoch(model, device, train_loader, optimizer, epoch)\n",
    "        test_one_epoch(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    # saving\n",
    "    torch.save(model.state_dict(), 'mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975aaed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T05:33:32.620609Z",
     "iopub.status.busy": "2022-04-24T05:33:32.620401Z",
     "iopub.status.idle": "2022-04-24T05:33:32.630771Z",
     "shell.execute_reply": "2022-04-24T05:33:32.630027Z",
     "shell.execute_reply.started": "2022-04-24T05:33:32.620585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, device, train_loader, optimizer, epoch, log_interval=100):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in tqdm.tqdm_notebook(enumerate(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target) # no softmax! F.cross_entropy = CE(Softmax(x))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Train epoch: {epoch} [Iter: {batch_idx*len(data)}/{len(train_loader.dataset)}]' + \\\n",
    "                  f'\\t Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37140b76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T05:33:32.632719Z",
     "iopub.status.busy": "2022-04-24T05:33:32.632507Z",
     "iopub.status.idle": "2022-04-24T05:33:32.648060Z",
     "shell.execute_reply": "2022-04-24T05:33:32.647223Z",
     "shell.execute_reply.started": "2022-04-24T05:33:32.632696Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_one_epoch(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('-' * 10)\n",
    "    print(f'Test: Average loss:{test_loss:.4f}, ' + \\\n",
    "          f'Accuracy: {100. * correct/len(test_loader.dataset):.0f}%')\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a993f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T05:33:32.649439Z",
     "iopub.status.busy": "2022-04-24T05:33:32.649199Z",
     "iopub.status.idle": "2022-04-24T05:36:05.709216Z",
     "shell.execute_reply": "2022-04-24T05:36:05.708307Z",
     "shell.execute_reply.started": "2022-04-24T05:33:32.649412Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5d94fc3252443ab922c38c16952a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 [Iter: 0/60000]\t Loss: 2.290933\n",
      "Train epoch: 1 [Iter: 6400/60000]\t Loss: 0.262079\n",
      "Train epoch: 1 [Iter: 12800/60000]\t Loss: 0.421512\n",
      "Train epoch: 1 [Iter: 19200/60000]\t Loss: 0.247179\n",
      "Train epoch: 1 [Iter: 25600/60000]\t Loss: 0.074998\n",
      "Train epoch: 1 [Iter: 32000/60000]\t Loss: 0.175338\n",
      "Train epoch: 1 [Iter: 38400/60000]\t Loss: 0.113575\n",
      "Train epoch: 1 [Iter: 44800/60000]\t Loss: 0.033929\n",
      "Train epoch: 1 [Iter: 51200/60000]\t Loss: 0.080976\n",
      "Train epoch: 1 [Iter: 57600/60000]\t Loss: 0.117306\n",
      "----------\n",
      "Test: Average loss:0.0740, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ae20fcdbce450cb51f44f607d5a6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 2 [Iter: 0/60000]\t Loss: 0.135707\n",
      "Train epoch: 2 [Iter: 6400/60000]\t Loss: 0.116474\n",
      "Train epoch: 2 [Iter: 12800/60000]\t Loss: 0.131173\n",
      "Train epoch: 2 [Iter: 19200/60000]\t Loss: 0.050226\n",
      "Train epoch: 2 [Iter: 25600/60000]\t Loss: 0.108192\n",
      "Train epoch: 2 [Iter: 32000/60000]\t Loss: 0.070618\n",
      "Train epoch: 2 [Iter: 38400/60000]\t Loss: 0.042846\n",
      "Train epoch: 2 [Iter: 44800/60000]\t Loss: 0.155448\n",
      "Train epoch: 2 [Iter: 51200/60000]\t Loss: 0.178205\n",
      "Train epoch: 2 [Iter: 57600/60000]\t Loss: 0.050348\n",
      "----------\n",
      "Test: Average loss:0.0603, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd68af3632b4b3587f12dddee89707d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 3 [Iter: 0/60000]\t Loss: 0.036096\n",
      "Train epoch: 3 [Iter: 6400/60000]\t Loss: 0.049126\n",
      "Train epoch: 3 [Iter: 12800/60000]\t Loss: 0.052084\n",
      "Train epoch: 3 [Iter: 19200/60000]\t Loss: 0.060259\n",
      "Train epoch: 3 [Iter: 25600/60000]\t Loss: 0.033311\n",
      "Train epoch: 3 [Iter: 32000/60000]\t Loss: 0.027373\n",
      "Train epoch: 3 [Iter: 38400/60000]\t Loss: 0.028097\n",
      "Train epoch: 3 [Iter: 44800/60000]\t Loss: 0.091322\n",
      "Train epoch: 3 [Iter: 51200/60000]\t Loss: 0.060410\n",
      "Train epoch: 3 [Iter: 57600/60000]\t Loss: 0.058623\n",
      "----------\n",
      "Test: Average loss:0.0588, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33cf200d60f45a99b1632aea70f7ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 4 [Iter: 0/60000]\t Loss: 0.030468\n",
      "Train epoch: 4 [Iter: 6400/60000]\t Loss: 0.010301\n",
      "Train epoch: 4 [Iter: 12800/60000]\t Loss: 0.016564\n",
      "Train epoch: 4 [Iter: 19200/60000]\t Loss: 0.059626\n",
      "Train epoch: 4 [Iter: 25600/60000]\t Loss: 0.017018\n",
      "Train epoch: 4 [Iter: 32000/60000]\t Loss: 0.032318\n",
      "Train epoch: 4 [Iter: 38400/60000]\t Loss: 0.064526\n",
      "Train epoch: 4 [Iter: 44800/60000]\t Loss: 0.061452\n",
      "Train epoch: 4 [Iter: 51200/60000]\t Loss: 0.017773\n",
      "Train epoch: 4 [Iter: 57600/60000]\t Loss: 0.058905\n",
      "----------\n",
      "Test: Average loss:0.0587, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f3d16d88754523acc7e00e13e178ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 5 [Iter: 0/60000]\t Loss: 0.055722\n",
      "Train epoch: 5 [Iter: 6400/60000]\t Loss: 0.123555\n",
      "Train epoch: 5 [Iter: 12800/60000]\t Loss: 0.021306\n",
      "Train epoch: 5 [Iter: 19200/60000]\t Loss: 0.199588\n",
      "Train epoch: 5 [Iter: 25600/60000]\t Loss: 0.144897\n",
      "Train epoch: 5 [Iter: 32000/60000]\t Loss: 0.086718\n",
      "Train epoch: 5 [Iter: 38400/60000]\t Loss: 0.027593\n",
      "Train epoch: 5 [Iter: 44800/60000]\t Loss: 0.038253\n",
      "Train epoch: 5 [Iter: 51200/60000]\t Loss: 0.025756\n",
      "Train epoch: 5 [Iter: 57600/60000]\t Loss: 0.066233\n",
      "----------\n",
      "Test: Average loss:0.0587, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99d0408e10041cfbe76ccbfc05e4f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 6 [Iter: 0/60000]\t Loss: 0.035878\n",
      "Train epoch: 6 [Iter: 6400/60000]\t Loss: 0.069505\n",
      "Train epoch: 6 [Iter: 12800/60000]\t Loss: 0.059408\n",
      "Train epoch: 6 [Iter: 19200/60000]\t Loss: 0.040360\n",
      "Train epoch: 6 [Iter: 25600/60000]\t Loss: 0.017304\n",
      "Train epoch: 6 [Iter: 32000/60000]\t Loss: 0.051150\n",
      "Train epoch: 6 [Iter: 38400/60000]\t Loss: 0.135936\n",
      "Train epoch: 6 [Iter: 44800/60000]\t Loss: 0.053987\n",
      "Train epoch: 6 [Iter: 51200/60000]\t Loss: 0.103070\n",
      "Train epoch: 6 [Iter: 57600/60000]\t Loss: 0.029660\n",
      "----------\n",
      "Test: Average loss:0.0587, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05335c4a5a84197a8098dedf490cfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 7 [Iter: 0/60000]\t Loss: 0.022966\n",
      "Train epoch: 7 [Iter: 6400/60000]\t Loss: 0.042366\n",
      "Train epoch: 7 [Iter: 12800/60000]\t Loss: 0.101577\n",
      "Train epoch: 7 [Iter: 19200/60000]\t Loss: 0.034983\n",
      "Train epoch: 7 [Iter: 25600/60000]\t Loss: 0.015327\n",
      "Train epoch: 7 [Iter: 32000/60000]\t Loss: 0.050052\n",
      "Train epoch: 7 [Iter: 38400/60000]\t Loss: 0.012108\n",
      "Train epoch: 7 [Iter: 44800/60000]\t Loss: 0.107480\n",
      "Train epoch: 7 [Iter: 51200/60000]\t Loss: 0.084626\n",
      "Train epoch: 7 [Iter: 57600/60000]\t Loss: 0.192875\n",
      "----------\n",
      "Test: Average loss:0.0587, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38482679a62445cca3a34f58eabf5ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 8 [Iter: 0/60000]\t Loss: 0.039832\n",
      "Train epoch: 8 [Iter: 6400/60000]\t Loss: 0.030785\n",
      "Train epoch: 8 [Iter: 12800/60000]\t Loss: 0.022965\n",
      "Train epoch: 8 [Iter: 19200/60000]\t Loss: 0.119799\n",
      "Train epoch: 8 [Iter: 25600/60000]\t Loss: 0.062288\n",
      "Train epoch: 8 [Iter: 32000/60000]\t Loss: 0.137041\n",
      "Train epoch: 8 [Iter: 38400/60000]\t Loss: 0.092392\n",
      "Train epoch: 8 [Iter: 44800/60000]\t Loss: 0.027005\n",
      "Train epoch: 8 [Iter: 51200/60000]\t Loss: 0.068983\n",
      "Train epoch: 8 [Iter: 57600/60000]\t Loss: 0.037548\n",
      "----------\n",
      "Test: Average loss:0.0587, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4ae41f226e462aa4a65e7042e31b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 9 [Iter: 0/60000]\t Loss: 0.036981\n",
      "Train epoch: 9 [Iter: 6400/60000]\t Loss: 0.064872\n",
      "Train epoch: 9 [Iter: 12800/60000]\t Loss: 0.143403\n",
      "Train epoch: 9 [Iter: 19200/60000]\t Loss: 0.057350\n",
      "Train epoch: 9 [Iter: 25600/60000]\t Loss: 0.086227\n",
      "Train epoch: 9 [Iter: 32000/60000]\t Loss: 0.046821\n",
      "Train epoch: 9 [Iter: 38400/60000]\t Loss: 0.029497\n",
      "Train epoch: 9 [Iter: 44800/60000]\t Loss: 0.042612\n",
      "Train epoch: 9 [Iter: 51200/60000]\t Loss: 0.063328\n",
      "Train epoch: 9 [Iter: 57600/60000]\t Loss: 0.013613\n",
      "----------\n",
      "Test: Average loss:0.0587, Accuracy: 98%\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc9417185a0476896899652238945c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 10 [Iter: 0/60000]\t Loss: 0.054516\n",
      "Train epoch: 10 [Iter: 6400/60000]\t Loss: 0.037694\n",
      "Train epoch: 10 [Iter: 12800/60000]\t Loss: 0.028837\n",
      "Train epoch: 10 [Iter: 19200/60000]\t Loss: 0.024753\n",
      "Train epoch: 10 [Iter: 25600/60000]\t Loss: 0.032908\n",
      "Train epoch: 10 [Iter: 32000/60000]\t Loss: 0.060467\n",
      "Train epoch: 10 [Iter: 38400/60000]\t Loss: 0.043509\n",
      "Train epoch: 10 [Iter: 44800/60000]\t Loss: 0.059246\n",
      "Train epoch: 10 [Iter: 51200/60000]\t Loss: 0.074750\n",
      "Train epoch: 10 [Iter: 57600/60000]\t Loss: 0.074909\n",
      "----------\n",
      "Test: Average loss:0.0587, Accuracy: 98%\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_on_MNIST()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559bfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
